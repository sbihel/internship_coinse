\documentclass{llncs2e/llncs}
\usepackage{makeidx}  % allows for indexgeneration

\usepackage[pdftex]{graphicx}
\graphicspath{{images/}}

\usepackage{hyperref}
\usepackage{url} \urlstyle{sf}

\usepackage{color}
\def\todo#1{{\color{red}TODO:\quad#1}}
\def\addref#1{{\color{red}$[$#1$]$}}

\usepackage{datetime}
\newdate{startdate}{15}{05}{2017}
\newdate{enddate}{04}{08}{2017}

\title{Automated Test Data Generation for Dynamically Typed Programming Languages}
\titlerunning{Automated Test Data Generation for Dynamically Typed Programming Languages}

\author{Simon Bihel\inst{1, 2}}
\authorrunning{Simon Bihel}
\institute{Universit\'e de Rennes 1, France \and \'Ecole Normale Sup\'erieure de Rennes, France\\
\email{\href{mailto:simon.bihel@ens-rennes.fr}{simon.bihel@ens-rennes.fr}}}

\begin{document}
\pagestyle{headings}  % switches on printing of running heads
\mainmatter%          % start of the contributions

\maketitle

\hrulefill%

\begin{center}
  \textbf{Supervisor:} Dr.\ Shin Yoo\\
  COINSE Lab, KAIST, South-Korea
\end{center}

\hrulefill%

\begin{center}
  \displaydate{startdate} --- \displaydate{enddate}
\end{center}

\vfill

\centerline{%
    \includegraphics[width=0.3\textwidth]{Logo_ENS_Rennes}
    \hspace{0.05\textwidth}
    \raisebox{1\height}{\includegraphics[width=0.3\textwidth]{Universite_Rennes_1_logo}}
    \hspace{0.05\textwidth}
    \includegraphics[width=0.3\textwidth]{KAIST_logo}
    \hspace{0.05\textwidth}
    \includegraphics[width=0.3\textwidth]{RB_NB}
}

\vfill

\begin{abstract}
  \todo{}
Despite popular usage, most of the dynamically typed languages still lack
automated test data generation tools.  Most of the existing tools and
approaches depend critically on static and explicit types, which makes it hard
to port any of them over to dynamically typed languages. In this paper we
present a search-based test data generation tool, NAME, which focuses on
primitive types and lists of Python. NAME not only searches for test input
values but also for appropriate types for each input argument. We evaluate NAME
based on the structural coverage it achieves, the cost of the type search, and
the overhead for the execution of the function under test. We further discuss
the future of automated testing for dynamic and object-oriented languages based
on our experience.
\keywords{software engineering, testing, coverage, experimental, dynamic typing}
\end{abstract}
%
\newpage


\section{Introduction}
\todo{}

\addref{}

Testing is an essential part of software development. Especially due to the lack
of formal specifications, tests are the pillars to ensure well-behavior of
programs, be it lack of crash or coherent results. Various metrics exist to
evaluate how thoroughly tested a software is. One of these is the \textit{code
coverage} that describes the degree to which the source code of a program is
executed when a particular test suite runs.

Automating the generation of tests is essential to free the programmer from
writing them as is it a time-consuming and error-prone task. Evolutionary
methods like search-based software testing have been of interest for several
decades~\cite{miller1976automatic}. In particular, the automated test data
generation problem~\cite{korel1990automated} which consists of generating inputs
to explore different kinds of properties for a given program.

Past works on test generation automation have been focused on statically-typed
languages (more details in Section~\ref{relatedwork}). Having information on the
type of test inputs allows tools to focus on the values of inputs and the depth
of complex structures. Having no knowledge on the inputs induces limitations to
the kind of bugs a tool can detects as well as a heavier cost due to tries with
wrongly typed inputs. Those challenges are described more in depth in
Section~\ref{challenges}.

This paper presents a method to automatically test dynamically-typed languages
(with minimal requirements on the properties of the language)
(Section~\ref{contribution}). We implemented it as a tool call NAME for the
Python language. An evaluation can be found in Section~\ref{evaluation}. Many
problems are still left with for example the generation of objects as dynamic
languages are often Object-Oriented, and future paths of work are put down in
Section~\ref{futureworks}.


\section{Related Works}
\label{relatedwork}
\todo{}

While a lot of work has been put in automated testing for statically typed
languages, dynamically typed languages have received very little attention. Only
a few projects exist and each has different approach, with different levels of
automation, and using different properties that usually come with dynamic
languages.

Multiple reasons can explain this void. Culturally, languages like Python are
not under the same level of industrial scrutiny for structural coverage,
compared to C or Java. But with rise of significant projects written with
dynamic languages the light is moving toward this problem. These projects range
from popular web applications to scientific tools. Despite this interest the
automation of tests generation is still a daunting task.

Before presenting others automated testing tools in~\ref{related_research} we
will first give an overview of search-based software engineering in~\ref{st},~\ref{sbse}
and explain some techniques used in general for dynamic languages testing
in~\ref{techniques}.

\subsection{Software testing}
\label{st}

There are a broad variety of test and metric classes. Tests have to be focused
on one particular aspect of software to be finer grained, faster to run, to be
more comprehensible in the bugs they find, have more precise goals to achieve
for developer\dots\ Like many things we want to classify and abstract concepts.

As we are interested in automated testing, where a tool generates tests without
the help of the programmer, we can identify some test classes. We will focus on
dynamic testing, as opposed to static testing (e.g.\ static analysis). We have
two kinds of testing, black-box and white-box. We will focus on white-box but we
will present both.

\paragraph{Black-box testing} It consists of analysing only the inputs and
outputs of the System Under Test (SUT). It is used to test functionalities,
integration in other systems or even purely random testing. The last one is
useful to discover failure domains~\cite{ahmad2014new}.

Because we are focusing on the problem of automated testing without much
information of what the SUT should do we will not be focusing on this kind of
testing.

\paragraph{White-box testing} On the other hand, with more information on the
SUT (e.g.\ its source code or runtime) we can have more insightful feedbacks. We
can different units (i.e.\ parts) of the software, analyze the data and control
flow, or test only modified parts by what is called regression. With access to
the innards of the SUT we can make sure that every parts of it are tested. We
use a metric called \textit{code coverage} to evaluate the scope of tests.

%BRANCH COVERAGE
Multiple coverage criteria exist: Has every function been called? Has each
statement been executed? Has each boolean sub-expression been evaluated both to
true and false? Has each branch of each control structure been executed? That
last criterion is called branch coverage and it is the one we are focusing one.
It is part of standards~\cite{BSI98,RTCA92} for quality assurance and safety.

In our case with dynamically-typed languages, working on code coverage seems to
be a good idea to make sure we are exploring every functionalities of a function
as they might be dependent on the type of parameters. This particular problem of
exploring every branch of a function is called test data generation and one way
to tackle this is to use search-based techniques.

\subsection{Search-based software engineering}
\label{sbse}

When we are trying to explore different branches, we are trying to satisfy some
boolean conditions. We will thus try to find values that can reach and pass
these control structure. With feedback to know how close we are to go through a
condition we can iterate, tweak parameters and re-execute the SUT\@. This way of
solving appeared in 1990~\cite{korel1990automated} and is called
\textit{search-based test data generation}. It has been extensively applied to
branch coverage~\cite{mcminn2004search,lakhotia2007multi,mcminn2007iguana}.

One example is the Alternating Variable Method~\cite{mcminn2016avmf} that
consists in playing with one parameter until no positive change is seen, and
then focus on another parameter.

% it is justified to use in our case because we cannot deduce everything from
% static analysis or symbolic execution

\subsection{Testing techniques} % in dynamic languages}
\label{techniques}

Following is a list of testing methods that the reader can refer to understand
the scope of related tools.

\paragraph{Instrumentation} Instrumentation code is code that is traditionally
insert in the SUT during compilation or linking. This code can provide various
information like counters to record which statement are executed or compute
distances as needed in branch coverage search.

\paragraph{Mock objects} simulate to behavior of real objects. They are used to
have more control on the execution, e.g.\ to remove some side effects to test
one particular property of a program or simply to provide instrumentation. It is
a versatile tool vastly used in the
industry~\cite{mackinnon2000endo,taneja2010moda,freeman2004mock,tillmann2006mock}.

% talk about the fact that you can't mock everyhing in python as in ruby e.g.

\subsection{Research works}
\label{related_research}

% no \citeauthor or \citet with llncs :(
Ducasse et al.~\cite{ducasse2011challenges} have already exposed challenges and
milestones in random testing of dynamically-typed languages. Our work exposes
more practical details which are explained in the next section.

RuTeG~\cite{mairhofer2011search} is a Ruby tool that uses search-based
techniques. It is not fully automated as it requires the user to provide
different generators for specific problems for complex data.

% should I say that it is a student project?
SpLATS~\cite{splats} is another tool for Ruby that was written during a student
project. It has a lazy approach and uses mock objects for that purpose. It will
collect information at runtime on which methods should be implemented and will
output most of the time other mock objects or else primitives.

SPLAT~\cite{splat} is a tool for Python with a lazy approach and is another
student project. One particularity is that it uses bytecode.

These works were published around 5 years ago but without follow-up. While our
tool has hardly anything new, we aim at building precise foundations to build on
in future works. In addition to that, as each of these projects have different
problematics depending on the language they are tackling, we aim to identify
some generalization for dynamically-typed languages.


% does it make sense to do branch coverage on dynamic languages?

\section{Challenges}
\label{challenges}
\todo{}

This section presents challenges of testing dynamically-typed languages based on
previous research~\cite{ducasse2011challenges} and our experience.

\subsection{Pure dynamic types problems}
\paragraph{Type errors} One big limitation for an automated code coverage tester
is the inability to identify crashes. As we are trying to find coherent types
for parameters, if a type error is raised, how can we know it is the parameters
that are the problem and not the code?

\paragraph{Relations between parameters} Parameters search can get incredibly
complex if we think even beyond complex data structures, with for example
functions.

\paragraph{Working but unfit types} A parameter of a certain type might not
generate type errors but make the search much more difficult. If we have for
example a floating-point number where an integer then simply approaching a round
value might be difficult.

\subsection{The bigger picture}
% non-problems?
\paragraph{Instance generation and execution} When dealing with complex data
structures like objects you might not have easy access to an initialization
method.
% no constructors in smalltalk -> close to what we do with just lists? methods?
% still falls in our handling of type errors?

\paragraph{Understanding results} In a case outside of simple code coverage, you
might want to analyze the result and judge whether it is right. If a function
ends up working for different parameters types than the ones it was designed for
we are facing the oracle problem~\cite{barr2015oracle}.


\section{Contribution}
\label{contribution}
\todo{}

Sortof fork of~\cite{Kim2017ts}
% minimal use of dynamic language features, focus on dynamic types
% just primitive types and lists

\subsection{Philosophy}
\label{philosophy}

\subsection{Technical difficulties}
\label{tech_difficulties}


% \section{Evaluation}
% \label{evaluation}
% \todo{}

% try on libraries that don't use complex data structures, like math libraries
% and such?


\section{Future Works}
\label{futureworks}
\todo{}

\cite{gligoric2011smutant,haupt2011type,steinert2010continuous,yoo2012regression}% regression testing
% use annotations?
\cite{chugh2012nested}% verification if you know the type
\cite{chambers1991iterative}%

\cite{hayes1994testing}% OO  TODO

\cite{bottaci2010type} %TODO

\section{Conclusion}
\label{conclusion}
\todo{}


\section*{Acknowledgment}
Thanks to Shin Yoo and the whole COINSE team that has been very friendly and
welcoming. Thanks also to KAIST for hosting me.

This internship was supported by the R\'egion Bretagne with the \textit{Jeune
\`a l'International} grant as well as the ENS Rennes with the \textit{Aide
Transport pour la Mobilit\'e \`a l'International} grant.

\bibliographystyle{llncs2e/splncs03}
\bibliography{biblio}

\end{document}
